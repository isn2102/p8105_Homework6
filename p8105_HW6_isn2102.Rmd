---
title: "p8105_hw6_isn2102.Rmd"
author: "Isabel Nelson"
date: "11/22/2020"
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(patchwork)
library(modelr)
library(mgcv)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
set.seed(1)
```

### Problem 2 

Import and clean data: 
```{r, message = FALSE}
birthweight_df <- 
  read_csv("./data/birthweight.csv") %>% 
  mutate(
    babysex = as.factor(babysex), 
    frace = as.factor(frace), 
    malform = as.factor(malform), 
    mrace = as.factor(mrace)
  ) 
```

Check for missing variables: none. 
```{r}
na_summary <- 
  birthweight_df %>% 
  summarise(babysex_na = sum(is.na(babysex)), 
            bhead_na = sum(is.na(bhead)),
            blength_na = sum(is.na(blength)),
            bwt_na = sum(is.na(bwt)),
            delwt_na = sum(is.na(delwt)),
            fincome_na = sum(is.na(fincome)),
            frace_na = sum(is.na(frace)),
            gaweeks_na = sum(is.na(gaweeks)),
            malform_na = sum(is.na(malform)),
            menarche_na = sum(is.na(menarche)),
            mheigth_na = sum(is.na(mheight)),
            momage_na = sum(is.na(momage)),
            mrace_na = sum(is.na(mrace)),
            parity_na = sum(is.na(parity)),
            pnumlbw_na = sum(is.na(pnumlbw)),
            pnumgsa_na = sum(is.na(pnumsga)),
            ppbmi_na = sum(is.na(ppbmi)),
            ppwt_na = sum(is.na(ppwt)),
            smoken_na = sum(is.na(smoken)),
            wtgain_na = sum(is.na(wtgain)),
  )
na_summary %>% knitr::kable(digits = 5)
```

**Model building process:**  

1. Select a subset of variables that are expected to be related to birthweight based on theoretical knowledge: bhead, blength, delwt, fincome, gaweeks, momage, mrace, pnumlbw, pnumsga, ppbmi, smoken, wtgain  

2. Look at plots to see the relationship between each possible predictor and the outcome. Choose predictors that have a linear relationship with the outcome to move forward.   
```{r}
bhead_plot <-
birthweight_df %>% 
  ggplot(aes(x = bhead, y = bwt)) + 
  geom_point()
blength_plot <-
birthweight_df %>% 
  ggplot(aes(x = blength, y = bwt)) + 
  geom_point()
delwt_plot <-
birthweight_df %>% 
  ggplot(aes(x = delwt, y = bwt)) + 
  geom_point()
fincome_plot <-
birthweight_df %>% 
  ggplot(aes(x = fincome, y = bwt)) + 
  geom_point()
gaweeks_plot <-
birthweight_df %>% 
  ggplot(aes(x = gaweeks, y = bwt)) + 
  geom_point()
momage_plot <-
birthweight_df %>% 
  ggplot(aes(x = momage, y = bwt)) + 
  geom_point()
mrace_plot <-
birthweight_df %>% 
  ggplot(aes(x = mrace, y = bwt)) + 
  geom_point()
pnumlbw_plot <-
birthweight_df %>% 
  ggplot(aes(x = pnumlbw, y = bwt)) + 
  geom_point()
pnumsga_plot <-
birthweight_df %>% 
  ggplot(aes(x = pnumsga, y = bwt)) + 
  geom_point()
ppbmi_plot <-
birthweight_df %>% 
  ggplot(aes(x = ppbmi, y = bwt)) + 
  geom_point()
smoken_plot <-
birthweight_df %>% 
  ggplot(aes(x = smoken, y = bwt)) + 
  geom_point()
wtgain_plot <-
birthweight_df %>% 
  ggplot(aes(x = wtgain, y = bwt)) + 
  geom_point()

(bhead_plot + blength_plot + delwt_plot + fincome_plot + gaweeks_plot + momage_plot + mrace_plot + pnumlbw_plot + pnumsga_plot + ppbmi_plot + smoken_plot + wtgain_plot + plot_layout(ncol = 4))
```

From these plots we see that pnumlbw and pnumsga only have one value each for all observations (zero), so we will remove those two. Additionally, it looks like wtgain is not linear so we will remove that as well. Mrace can be coded as dummy variables so we will keep that in the model for now.  


3. Fit a bivariate linear model for each variable, and choose variables that seem like they may have a substantial relationship.
```{r}
bhead_biv <- lm(bwt ~ bhead, data = birthweight_df)
broom::tidy(bhead_biv) %>% knitr::kable(digits = 5)

blength_biv <- lm(bwt ~ blength, data = birthweight_df)
broom::tidy(blength_biv) %>% knitr::kable(digits = 5)

delwt_biv <- lm(bwt ~ delwt, data = birthweight_df)
broom::tidy(delwt_biv) %>% knitr::kable(digits = 5)

fincome_biv <- lm(bwt ~ fincome, data = birthweight_df)
broom::tidy(fincome_biv) %>% knitr::kable(digits = 5)

gaweeks_biv <- lm(bwt ~ gaweeks, data = birthweight_df)
broom::tidy(gaweeks_biv) %>% knitr::kable(digits = 5)

momage_biv <- lm(bwt ~ momage, data = birthweight_df)
broom::tidy(momage_biv) %>% knitr::kable(digits = 5)

mrace_biv <- lm(bwt ~ mrace, data = birthweight_df)
broom::tidy(mrace_biv) %>% knitr::kable(digits = 5)

ppbmi_biv <- lm(bwt ~ ppbmi, data = birthweight_df)
broom::tidy(ppbmi_biv) %>% knitr::kable(digits = 5)

smoken_biv <- lm(bwt ~ smoken, data = birthweight_df)
broom::tidy(smoken_biv) %>% knitr::kable(digits = 5)
```

From this exploration we can see that all variables tested had p-values that were very small (most show up as zero). 

4. Fit a preliminary model with all these predictors.  
```{r}
prelim_model <- lm(bwt ~ bhead + blength + delwt + fincome + gaweeks + momage + mrace + ppbmi + smoken, data = birthweight_df)
```

5. Look at the t test statistic for each variable to see significant ones. Also remove predictor from model and if the other parameter estimates change, keep variable in the model. Remove variables that do not change other estimates much when removing them, or with insignificant p-values.  
```{r}
summary(prelim_model) 

prelim_model2 <- lm(bwt ~ bhead + blength + delwt + gaweeks + mrace + ppbmi + smoken, data = birthweight_df)
summary(prelim_model2)

prelim_model3 <- lm(bwt ~ bhead + blength + delwt + gaweeks + ppbmi + mrace, data = birthweight_df)
summary(prelim_model3)

prelim_model4 <- lm(bwt ~ bhead + blength + delwt + gaweeks + mrace, data = birthweight_df)
summary(prelim_model4)

prelim_model5 <- lm(bwt ~ bhead + blength + gaweeks + mrace, data = birthweight_df)
summary(prelim_model5)
```

From this regression output we see that fincome and momage are not significant anymore so we will remove those. I removed smoken, delwt, and ppbmi variables and the other coefficients didn't change much, and the R^2 is still very high (0.70 compared to 0.72 with the "full" model) so I will keep those variables out of model. My final model includes bhead, blength, gaweeks, and mrace.

Plot model residuals against fitted values:
```{r}
birthweight_df %>% 
add_residuals(prelim_model5) %>% 
add_predictions(prelim_model5) %>% 
ggplot(aes(x = pred, y = resid)) + 
geom_point()
```

**Interpretation??**  


Fit two additional models: 
```{r}
model_blength_gaweeks <- lm(bwt ~ blength + gaweeks, data = birthweight_df)
summary(model_blength_gaweeks)
model_interactions <- lm(bwt ~ bhead * blength * babysex, data = birthweight_df)
summary(model_interactions)
```

Compare the three models by using a cross-validation approach. First create a set of ten samples with crossv_mc, then convert to tibbles. Map each model across each sample dataframe, then calculate RMSE based on each fitted model and the testing portion of each sample from the original dataset. 
```{r}
cv_bw_df <- 
  crossv_mc(birthweight_df, 10)

cv_bw_df <-  
  cv_bw_df %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )

cv_bw_df <- 
  cv_bw_df %>% 
  mutate(
    interactions_mod = map(.x = train, ~lm(bwt ~ bhead * blength * babysex, data = .x)),
    blength_gaweeks_mod = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    prelim5_mod = map(.x = train, ~lm(bwt ~ bhead + blength + gaweeks + mrace, data = .x))
  ) %>% 
  mutate(
    rmse_interactions = map2_dbl(.x = interactions_mod, .y = test, ~rmse(model = .x, data = .y)),
    rmse_blength_gaweeks = map2_dbl(.x = blength_gaweeks_mod, .y = test, ~rmse(model = .x, data = .y)),
    rmse_prelim5 = map2_dbl(.x = prelim5_mod, .y = test, ~rmse(model = .x, data = .y))
  )
```

Assess RMSE to see which model is best. Pivot data to tidy, visualize distribution, and calculate the mean RMSE.
```{r}
cv_bw_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_violin()

cv_bw_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  group_by(model) %>% 
  summarize(avg_rmse = mean(rmse)) %>% 
  knitr::kable(digits = 5)
  
```

Because the smallest distribution of RMSE is for the prelim5 model which I initially fit, and because we can see that prelim5 also has the smallest average RMSE, we can conclude that prelim5 predicts birthweight the best in our test data.


### Problem 3  

Create data and clean: 
```{r, message = FALSE}
weather_df <- 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

Use 5000 bootstrap samples and produce an estimate for r^2 and log(beta0xbeta1) for each bootstrap sample. First create a helper function to create log(beta0xbeta1) from the broom::tidy results. Then map my linear model with tmax and tmin, broom:glance, and my function to each bootstrap sample. Unnest results and select the ones I want.

```{r}
beta_extract = function(ls) {
  broom::tidy(ls) %>% 
  select(term, estimate) %>% 
    pivot_wider(names_from = term, values_from = estimate) %>% 
    janitor::clean_names() %>% 
    mutate(
      log_betas = log(intercept*tmin))
}
```

```{r}
bs_weather_df <-
weather_df %>% 
  bootstrap(5000, id = "strap_number") %>% 
  mutate(
    models = map(.x = strap, ~lm(tmax ~ tmin, data = .x)), 
    b_results = map(models, beta_extract), 
    r_results = map(models, broom::glance)
  ) %>% 
  select(strap_number, b_results, r_results) %>% 
  unnest(b_results, r_results) %>% 
  select(strap_number, r.squared, log_betas)
```

Plot the distribution of the estimates.
```{r}
hist_r.squared <-
bs_weather_df %>% 
  ggplot(aes(x = r.squared)) +
  geom_density(fill = "mediumpurple", color = "mediumpurple", alpha = 0.8)

hist_log_betas <-
  bs_weather_df %>% 
  ggplot(aes(x = log_betas)) +
  geom_density(fill = "turquoise3",color = "turquoise3", alpha = 0.8)

hist_r.squared + hist_log_betas
```

The distribution of r.squared is bell-shaped but is skewed more to the left than a normal curve. It is centered around 0.91. The distribution of log(beta0*beta1) is more normally shaped and centered around 2.01. 


Find the 95% confidence intervals for the estimates. 
```{r}
bs_weather_df %>% 
  pivot_longer(
    r.squared:log_betas, 
    names_to = "Estimate", 
    values_to = "Value"
  ) %>% 
  group_by(Estimate) %>% 
  summarize(
    ci_lower = quantile(Value, 0.025),
    ci_upper = quantile(Value, 0.975)
  ) %>% 
  knitr::kable(digits = 5)
```

The 95% confidence interval for r^2 is (1.965, 2.059) and the 95% confidence interval for log(beta0*beta1) is (0.893, 0.927). 



